{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1038c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc8e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d967bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ffe59c",
   "metadata": {},
   "source": [
    "## Spark DataFrames Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80734121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d6fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/27 12:30:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Basics').getOrCreate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5226155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('people.json');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f65cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a975b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d863d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9d9b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+\n",
      "|summary|               age|   name|\n",
      "+-------+------------------+-------+\n",
      "|  count|                 2|      3|\n",
      "|   mean|              24.5|   null|\n",
      "| stddev|7.7781745930520225|   null|\n",
      "|    min|                19|   Andy|\n",
      "|    max|                30|Michael|\n",
      "+-------+------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a423a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c079ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = [StructField('age', IntegerType(),True),\n",
    "              StructField('name', StringType(), True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1de57a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_struc = StructType(fields=data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f11c6e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('people.json', schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97239c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b581af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e03536",
   "metadata": {},
   "source": [
    "## Spark DataFrame Basics Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c88c39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|null|\n",
      "|  30|\n",
      "|  19|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddf5fb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=None, name='Michael')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1e79ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['age', 'name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31788ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----------+\n",
      "| age|   name|double_age|\n",
      "+----+-------+----------+\n",
      "|null|Michael|      null|\n",
      "|  30|   Andy|        60|\n",
      "|  19| Justin|        38|\n",
      "+----+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('double_age', df['age'] * 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee6395f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|my_new_age|   name|\n",
      "+----------+-------+\n",
      "|      null|Michael|\n",
      "|        30|   Andy|\n",
      "|        19| Justin|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming a column\n",
    "df.withColumnRenamed('age', 'my_new_age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b81bd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b7d1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = spark.sql('SELECT * FROM REPORT')\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6ad3195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|Andy|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_results = spark.sql('SELECT * FROM REPORT WHERE AGE = 30')\n",
    "new_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "240e2216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_results = spark.sql('SELECT * FROM REPORT WHERE NAME = \"Michael\"')\n",
    "new_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d53e43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  NOMES|\n",
      "+-------+\n",
      "|Michael|\n",
      "|   Andy|\n",
      "| Justin|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_results = spark.sql('SELECT NAME AS NOMES FROM REPORT')\n",
    "new_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b87a6",
   "metadata": {},
   "source": [
    "## Spark DataFrame Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "774a3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('appl_stock.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e22d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62930afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac1f699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              OPEN|             CLOSE|\n",
      "+------------------+------------------+\n",
      "|        213.429998|        214.009998|\n",
      "|        214.599998|        214.379993|\n",
      "|        214.379993|        210.969995|\n",
      "|            211.75|            210.58|\n",
      "|        210.299994|211.98000499999998|\n",
      "|212.79999700000002|210.11000299999998|\n",
      "|209.18999499999998|        207.720001|\n",
      "|        207.870005|        210.650002|\n",
      "|210.11000299999998|            209.43|\n",
      "|210.92999500000002|            205.93|\n",
      "|        208.330002|        215.039995|\n",
      "|        214.910006|            211.73|\n",
      "|        212.079994|        208.069996|\n",
      "|206.78000600000001|            197.75|\n",
      "|202.51000200000001|        203.070002|\n",
      "|205.95000100000001|        205.940001|\n",
      "|        206.849995|        207.880005|\n",
      "|        204.930004|        199.289995|\n",
      "|        201.079996|        192.060003|\n",
      "|192.36999699999998|        194.729998|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('data')\n",
    "grab = spark.sql('SELECT OPEN, CLOSE FROM DATA WHERE CLOSE < 500')\n",
    "grab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80e5858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.filter('Close < 500').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36996ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|              OPEN|             CLOSE|\n",
      "+------------------+------------------+\n",
      "|        213.429998|        214.009998|\n",
      "|        214.599998|        214.379993|\n",
      "|        214.379993|        210.969995|\n",
      "|            211.75|            210.58|\n",
      "|        210.299994|211.98000499999998|\n",
      "|212.79999700000002|210.11000299999998|\n",
      "|209.18999499999998|        207.720001|\n",
      "|        207.870005|        210.650002|\n",
      "|210.11000299999998|            209.43|\n",
      "|210.92999500000002|            205.93|\n",
      "|        208.330002|        215.039995|\n",
      "|        214.910006|            211.73|\n",
      "|        212.079994|        208.069996|\n",
      "|206.78000600000001|            197.75|\n",
      "|202.51000200000001|        203.070002|\n",
      "|205.95000100000001|        205.940001|\n",
      "|        206.849995|        207.880005|\n",
      "|        204.930004|        199.289995|\n",
      "|        201.079996|        192.060003|\n",
      "|192.36999699999998|        194.729998|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Close'] < 500).select(['OPEN', 'CLOSE']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36eb32bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|      Date|              Open|      High|       Low|     Close|   Volume|         Adj Close|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|2010-01-22|206.78000600000001|207.499996|    197.16|    197.75|220441900|         25.620401|\n",
      "|2010-01-28|        204.930004|205.500004|198.699995|199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|202.199995|190.250002|192.060003|311488100|         24.883208|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('data')\n",
    "grab = spark.sql('SELECT * FROM DATA WHERE CLOSE < 200 AND OPEN > 200')\n",
    "grab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c57f2c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|      Date|              Open|      High|       Low|     Close|   Volume|         Adj Close|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "|2010-01-22|206.78000600000001|207.499996|    197.16|    197.75|220441900|         25.620401|\n",
      "|2010-01-28|        204.930004|205.500004|198.699995|199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|202.199995|190.250002|192.060003|311488100|         24.883208|\n",
      "+----------+------------------+----------+----------+----------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Close'] < 200) & (df['Open'] > 200)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7720e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------+------+------+---------+---------+\n",
      "|      Date|              Open|      High|   Low| Close|   Volume|Adj Close|\n",
      "+----------+------------------+----------+------+------+---------+---------+\n",
      "|2010-01-22|206.78000600000001|207.499996|197.16|197.75|220441900|25.620401|\n",
      "+----------+------------------+----------+------+------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Low'] == 197.16).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63819647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': '2010-01-22',\n",
       " 'Open': 206.78000600000001,\n",
       " 'High': 207.499996,\n",
       " 'Low': 197.16,\n",
       " 'Close': 197.75,\n",
       " 'Volume': 220441900,\n",
       " 'Adj Close': 25.620401}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In real world we'll be using more .collect() than .show()\n",
    "result = df.filter((df['Close'] < 200) & (df['Open'] > 200)).collect()\n",
    "row = result[0]\n",
    "row.asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aff46e",
   "metadata": {},
   "source": [
    "## Groupby and Aggregate Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2de859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Eggs').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23866f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('sales_info.csv', inferSchema=True, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cffebb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29c20502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Company|sum(Sales)|\n",
      "+-------+----------+\n",
      "|   APPL|    1480.0|\n",
      "|   GOOG|     660.0|\n",
      "|     FB|    1220.0|\n",
      "|   MSFT|     967.0|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Company').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa12754c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(Sales)|\n",
      "+----------+\n",
      "|    4327.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Sales': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e703c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing functions from spark\n",
    "from pyspark.sql.functions import countDistinct, avg, stddev, format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3a9f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|    Average Sales|\n",
      "+-----------------+\n",
      "|360.5833333333333|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "df.select(avg('Sales').alias('Average Sales')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce7dcedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   std|\n",
      "+------+\n",
      "|250.09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_std = df.select(stddev('Sales').alias('STD'))\n",
    "sales_std.select(format_number('STD', 2).alias('std')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cd8f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|     FB|   Carl|870.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bf5db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|120.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|     FB|   Carl|870.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ascending\n",
    "df.sort('Sales').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54f5a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|870.0|\n",
      "|   APPL|   Mike|750.0|\n",
      "|   MSFT|   Tina|600.0|\n",
      "|     FB|  Sarah|350.0|\n",
      "|   APPL|  Chris|350.0|\n",
      "|   GOOG|  Frank|340.0|\n",
      "|   APPL|   John|250.0|\n",
      "|   MSFT|Vanessa|243.0|\n",
      "|   GOOG|    Sam|200.0|\n",
      "|   APPL|  Linda|130.0|\n",
      "|   MSFT|    Amy|124.0|\n",
      "|   GOOG|Charlie|120.0|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descending\n",
    "df.sort(df['Sales'].desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e763e6",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b043f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('miss').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f9b4610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('ContainsNull.csv', header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c476bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9efe2b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9587c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a37c54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+\n",
      "|  Id|    Name|Sales|\n",
      "+----+--------+-----+\n",
      "|emp1|    John| null|\n",
      "|emp2|Nameless| null|\n",
      "|emp3|Nameless|345.0|\n",
      "|emp4|   Cindy|456.0|\n",
      "+----+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna('Nameless', subset=['Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3ddd093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling sales with it's mean\n",
    "from pyspark.sql.functions import mean\n",
    "mean_value = df.select(mean(df['Sales'])).collect()\n",
    "mean_sales = mean_value[0][0]\n",
    "df.fillna(mean_sales, subset=['Sales']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a2012",
   "metadata": {},
   "source": [
    "## Dates and Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9de0cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('dates').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b85d4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('appl_stock.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9fd0eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|      Date|      Open|      High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|213.429998|214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|214.599998|215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|214.379993|    215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|    211.75|212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|210.299994|212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "+----------+----------+----------+------------------+------------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2b7f29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|      Date|              Open|\n",
      "+----------+------------------+\n",
      "|2010-01-04|        213.429998|\n",
      "|2010-01-05|        214.599998|\n",
      "|2010-01-06|        214.379993|\n",
      "|2010-01-07|            211.75|\n",
      "|2010-01-08|        210.299994|\n",
      "|2010-01-11|212.79999700000002|\n",
      "|2010-01-12|209.18999499999998|\n",
      "|2010-01-13|        207.870005|\n",
      "|2010-01-14|210.11000299999998|\n",
      "|2010-01-15|210.92999500000002|\n",
      "|2010-01-19|        208.330002|\n",
      "|2010-01-20|        214.910006|\n",
      "|2010-01-21|        212.079994|\n",
      "|2010-01-22|206.78000600000001|\n",
      "|2010-01-25|202.51000200000001|\n",
      "|2010-01-26|205.95000100000001|\n",
      "|2010-01-27|        206.849995|\n",
      "|2010-01-28|        204.930004|\n",
      "|2010-01-29|        201.079996|\n",
      "|2010-02-01|192.36999699999998|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Date', 'Open']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0de18785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (dayofmonth, dayofyear, hour, month,\n",
    "                                   year, weekofyear, format_number, date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb1e11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.select(month(df['Date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0ce8a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|Year|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|2010|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|2010|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|2010|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|2010|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|2010|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|2010|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|2010|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|2010|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|2010|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|2010|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|2010|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|2010|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|2010|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|2010|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|2010|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|2010|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|2010|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|2010|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|2010|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|2010|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Average closing price per year\n",
    "# df.select(year(df['Date'])).show()\n",
    "new_df = df.withColumn('Year', year(df['date']))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f84bed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|        avg(Close)|\n",
      "+----+------------------+\n",
      "|2010| 259.8424600000002|\n",
      "|2011|364.00432532142867|\n",
      "|2012| 576.0497195640002|\n",
      "|2013| 472.6348802857143|\n",
      "|2014| 295.4023416507935|\n",
      "|2015|120.03999980555547|\n",
      "|2016|104.60400786904763|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = new_df.groupBy('Year').mean('Close').sort('Year')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b9b0ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|Year|Avg Closing Price|\n",
      "+----+-----------------+\n",
      "|2010|           259.84|\n",
      "|2011|           364.00|\n",
      "|2012|           576.05|\n",
      "|2013|           472.63|\n",
      "|2014|           295.40|\n",
      "|2015|           120.04|\n",
      "|2016|           104.60|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Formating the date\n",
    "result.select(['Year', format_number('avg(Close)',2).alias('Avg Closing Price')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39367779",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5494a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "96aae5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88af13f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/27 12:31:27 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    }
   ],
   "source": [
    "training = spark.read.format('libsvm').load('sample_linear_regression_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adf3da1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b4a8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='features', labelCol='label', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "960254b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/27 12:31:28 WARN Instrumentation: [3d78ca00] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/04/27 12:31:29 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eacaa8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_ae6edcd268be, numFeatures=10"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65bd4747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0073, 0.8314, -0.8095, 2.4412, 0.5192, 1.1535, -0.2989, -0.5129, -0.6197, 0.6956])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e041f7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14228558260358093"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a6acf563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 103.28843028724194\n",
      "MAE 8.145215527783876\n",
      "RMSE 10.16309157133015\n"
     ]
    }
   ],
   "source": [
    "training_summary = lrModel.summary\n",
    "print(f'MSE {training_summary.meanSquaredError}')\n",
    "print(f'MAE {training_summary.meanAbsoluteError}')\n",
    "print(f'RMSE {training_summary.rootMeanSquaredError}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cee4ba44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/27 12:31:29 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    }
   ],
   "source": [
    "# More realistic situation\n",
    "all_data = spark.read.format('libsvm').load('sample_linear_regression_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "891394a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_Data ,test_Data = all_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "682a6d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce8852ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0994380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/27 12:31:31 WARN Instrumentation: [157bb32d] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "correct_model = lr.fit(train_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2608cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 92.35451789178968\n",
      "MAE 7.748461498636588\n",
      "RMSE 9.61012579999813\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test_Data\n",
    "test_results = correct_model.evaluate(test_Data)\n",
    "print(f'MSE {test_results.meanSquaredError}')\n",
    "print(f'MAE {test_results.meanAbsoluteError}')\n",
    "print(f'RMSE {test_results.rootMeanSquaredError}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d9be5c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data = test_Data.select('features')\n",
    "unlabeled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28e7cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|          prediction|\n",
      "+--------------------+--------------------+\n",
      "|(10,[0,1,2,3,4,5,...|  -4.018219241145397|\n",
      "|(10,[0,1,2,3,4,5,...| 0.22167149908507836|\n",
      "|(10,[0,1,2,3,4,5,...|  0.4326704362926248|\n",
      "|(10,[0,1,2,3,4,5,...| -1.1406525170786395|\n",
      "|(10,[0,1,2,3,4,5,...| -1.9752427863157647|\n",
      "|(10,[0,1,2,3,4,5,...| -2.0460303884701196|\n",
      "|(10,[0,1,2,3,4,5,...|  -1.082514454061944|\n",
      "|(10,[0,1,2,3,4,5,...|  1.1292401075248064|\n",
      "|(10,[0,1,2,3,4,5,...|     1.9114382267721|\n",
      "|(10,[0,1,2,3,4,5,...| -1.4019502626208762|\n",
      "|(10,[0,1,2,3,4,5,...|  1.8349841683798125|\n",
      "|(10,[0,1,2,3,4,5,...|  -2.198566771275138|\n",
      "|(10,[0,1,2,3,4,5,...|  3.9838190374263345|\n",
      "|(10,[0,1,2,3,4,5,...|  1.8727255223040917|\n",
      "|(10,[0,1,2,3,4,5,...|  -2.499417433656894|\n",
      "|(10,[0,1,2,3,4,5,...|  1.8822489143387113|\n",
      "|(10,[0,1,2,3,4,5,...|   3.737528486726122|\n",
      "|(10,[0,1,2,3,4,5,...|-0.39498580237356895|\n",
      "|(10,[0,1,2,3,4,5,...|  -1.589706299655978|\n",
      "|(10,[0,1,2,3,4,5,...|  0.3002095534565208|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = correct_model.transform(unlabeled_data)\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad182ba",
   "metadata": {},
   "source": [
    "#### Linear Regression Example Code Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b98f3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Lr').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "059baadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6125e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('Ecommerce_Customers.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a4e4a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avatar: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b93f0b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|Yearly Amount Spent|\n",
      "+-------------------+\n",
      "|  587.9510539684005|\n",
      "|  392.2049334443264|\n",
      "| 487.54750486747207|\n",
      "|  581.8523440352177|\n",
      "|  599.4060920457634|\n",
      "|   637.102447915074|\n",
      "|  521.5721747578274|\n",
      "|  549.9041461052942|\n",
      "|  570.2004089636196|\n",
      "|  427.1993848953282|\n",
      "|  492.6060127179966|\n",
      "|  522.3374046069357|\n",
      "|  408.6403510726275|\n",
      "|  573.4158673313865|\n",
      "|  470.4527333009554|\n",
      "|  461.7807421962299|\n",
      "| 457.84769594494855|\n",
      "| 407.70454754954415|\n",
      "|  452.3156754800354|\n",
      "|   605.061038804892|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict Yearly Amount Spent\n",
    "data.select('Yearly Amount Spent').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f165506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d26bd1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Email',\n",
       " 'Address',\n",
       " 'Avatar',\n",
       " 'Avg Session Length',\n",
       " 'Time on App',\n",
       " 'Time on Website',\n",
       " 'Length of Membership',\n",
       " 'Yearly Amount Spent']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3904ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputCols = Feature\n",
    "# outputCol = Label\n",
    "assembler = VectorAssembler(inputCols=['Avg Session Length',\n",
    "                             'Time on App',\n",
    "                             'Time on Website',\n",
    "                             'Length of Membership'],\n",
    "                           outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce2c0b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avatar: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(data)\n",
    "output.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a304b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            features|Yearly Amount Spent|\n",
      "+--------------------+-------------------+\n",
      "|[34.4972677251122...|  587.9510539684005|\n",
      "|[31.9262720263601...|  392.2049334443264|\n",
      "|[33.0009147556426...| 487.54750486747207|\n",
      "|[34.3055566297555...|  581.8523440352177|\n",
      "|[33.3306725236463...|  599.4060920457634|\n",
      "|[33.8710378793419...|   637.102447915074|\n",
      "|[32.0215955013870...|  521.5721747578274|\n",
      "|[32.7391429383803...|  549.9041461052942|\n",
      "|[33.9877728956856...|  570.2004089636196|\n",
      "|[31.9365486184489...|  427.1993848953282|\n",
      "|[33.9925727749537...|  492.6060127179966|\n",
      "|[33.8793608248049...|  522.3374046069357|\n",
      "|[29.5324289670579...|  408.6403510726275|\n",
      "|[33.1903340437226...|  573.4158673313865|\n",
      "|[32.3879758531538...|  470.4527333009554|\n",
      "|[30.7377203726281...|  461.7807421962299|\n",
      "|[32.1253868972878...| 457.84769594494855|\n",
      "|[32.3388993230671...| 407.70454754954415|\n",
      "|[32.1878120459321...|  452.3156754800354|\n",
      "|[32.6178560628234...|   605.061038804892|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = output.select('features', 'Yearly Amount Spent')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c80a51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test Split\n",
    "train_Data ,test_Data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f14ead72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ee65f7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aebbc8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/27 12:35:45 WARN Instrumentation: [c58af050] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/04/27 12:35:45 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/04/27 12:35:45 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(labelCol='Yearly Amount Spent')\n",
    "lr_model = lr.fit(train_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2e56c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|-18.819241175773946|\n",
      "|-20.106232273358504|\n",
      "| -20.30566147436103|\n",
      "| -18.52666609829308|\n",
      "|-15.828383402348752|\n",
      "|-15.448169968413223|\n",
      "|-16.244206278614005|\n",
      "|-16.991249435095366|\n",
      "|-17.634953839820668|\n",
      "|-14.035434530810342|\n",
      "| -17.19452904821249|\n",
      "|-13.150304384104116|\n",
      "|-17.756260599129206|\n",
      "|-14.364167599850505|\n",
      "| -8.539930374596933|\n",
      "|-12.482379256247745|\n",
      "|-14.093447087100802|\n",
      "| -9.900680133656351|\n",
      "| -8.302449628170244|\n",
      "|-10.108596256021178|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "259838ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 100.88587354405975\n",
      "MAE 7.901523141579479\n",
      "RMSE 10.044196012825504\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "test_result = lr_model.evaluate(test_Data)\n",
    "print(f'MSE {test_result.meanSquaredError}')\n",
    "print(f'MAE {test_result.meanAbsoluteError}')\n",
    "print(f'RMSE {test_result.rootMeanSquaredError}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b16ac237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|Yearly Amount Spent|\n",
      "+-------+-------------------+\n",
      "|  count|                500|\n",
      "|   mean|  499.3140382585909|\n",
      "| stddev|   79.3147815497068|\n",
      "|    min| 256.67058229005585|\n",
      "|    max|  765.5184619388373|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75708d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850231216769141"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my model explains 98% of the variance in this data\n",
    "test_result.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e954abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicing Deployment\n",
    "unlabeled_data = test_Data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "665a574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[29.5324289670579...|\n",
      "|[30.3931845423455...|\n",
      "|[30.5743636841713...|\n",
      "|[30.8794843441274...|\n",
      "|[30.9716756438877...|\n",
      "|[31.2606468698795...|\n",
      "|[31.2681042107507...|\n",
      "|[31.3895854806643...|\n",
      "|[31.5147378578019...|\n",
      "|[31.5316044825729...|\n",
      "|[31.5702008293202...|\n",
      "|[31.6005122003032...|\n",
      "|[31.6253601348306...|\n",
      "|[31.6610498227460...|\n",
      "|[31.7242025238451...|\n",
      "|[31.7366356860502...|\n",
      "|[31.7656188210424...|\n",
      "|[31.8124825597242...|\n",
      "|[31.8164283341993...|\n",
      "|[31.8512531286083...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5d716997",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c9e5c4c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[29.5324289670579...| 398.0010716406839|\n",
      "|[30.3931845423455...|332.02053460853745|\n",
      "|[30.5743636841713...| 441.7788666994559|\n",
      "|[30.8794843441274...|494.43224746154965|\n",
      "|[30.9716756438877...|487.89826221658404|\n",
      "|[31.2606468698795...|  422.730516944574|\n",
      "|[31.2681042107507...| 427.7769825383905|\n",
      "|[31.3895854806643...| 409.1522812868336|\n",
      "|[31.5147378578019...| 494.9801588065468|\n",
      "|[31.5316044825729...|433.13957083860237|\n",
      "|[31.5702008293202...| 563.9647761733197|\n",
      "|[31.6005122003032...|461.21852999510907|\n",
      "|[31.6253601348306...|381.55925736158724|\n",
      "|[31.6610498227460...|417.30223229787407|\n",
      "|[31.7242025238451...|510.01162281370193|\n",
      "|[31.7366356860502...|494.27651330332515|\n",
      "|[31.7656188210424...|501.12066342135836|\n",
      "|[31.8124825597242...| 396.5445126058346|\n",
      "|[31.8164283341993...| 519.5459437278741|\n",
      "|[31.8512531286083...|  465.064982461186|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a76df",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f4ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/27 15:56:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Logisti Reg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e1f2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d29d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/27 16:02:49 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('libsvm').load('sample_libsvm_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "343b8d0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb00121",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3beac556",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = log_model.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258c6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_summary = log.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebae1403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_summary.predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdb5fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train, lr_test = df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a1154c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_final = log_model.fit(lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df6764f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fit_final.evaluate(lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8ecc819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[95,96,97,12...|[17.3167238373939...|[0.99999996983923...|       0.0|\n",
      "|  0.0|(692,[98,99,100,1...|[22.5017389061392...|[0.99999999983110...|       0.0|\n",
      "|  0.0|(692,[121,122,123...|[26.0715340386861...|[0.99999999999524...|       0.0|\n",
      "|  0.0|(692,[122,123,124...|[14.9239377946288...|[0.99999966992242...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[34.8949304474571...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[32.3513316061859...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[21.0282594113961...|[0.99999999926287...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[30.8578849975642...|[0.99999999999996...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[11.3141563174258...|[0.99998780114564...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[33.3241081261198...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[16.7568609948152...|[0.99999994720561...|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[25.5813138418389...|[0.99999999999223...|       0.0|\n",
      "|  0.0|(692,[129,130,131...|[17.0376322423005...|[0.99999996012962...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[8.22045114274312...|[0.99973097875403...|       0.0|\n",
      "|  1.0|(692,[119,120,121...|[-1.5896648872024...|[0.16943105018012...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-22.353813534342...|[1.95822293352351...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-22.533252954833...|[1.63656245000632...|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-19.977016217564...|[2.10907532591749...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-22.320638298418...|[2.02427706386881...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-24.671073935903...|[1.92969524636586...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "040cee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bdcf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aefdb244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "my_final_roc = my_eval.evaluate(preds.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfd9640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_final_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa22c62",
   "metadata": {},
   "source": [
    "# Tree Methods Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df10b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe48f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/30 14:07:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('trees').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a73ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, DecisionTreeClassifier, GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e517df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/30 14:10:46 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.format('libsvm').load('sample_libsvm_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b578ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "851ce89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3dcd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier\n",
    "dtc = DecisionTreeClassifier(labelCol='label', featuresCol='features')\n",
    "\n",
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Gradient Boost Tree Classifier\n",
    "gbtc = GBTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82aefde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fitting the models\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbtc_model = gbtc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b79a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfr_preds = rfc_model.transform(test_data)\n",
    "gbtc_preds = gbtc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb003d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "acc_eval = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "print(f'DTC accuracy: {acc_eval.evaluate(dtc_preds)}')\n",
    "print(f'RFC accuracy: {acc_eval.evaluate(rfr_preds)}')\n",
    "print(f'GBTC accuracy: {acc_eval.evaluate(gbtc_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64afdc4",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93b3be",
   "metadata": {},
   "source": [
    "Examples & More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd40d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c815e392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/03 11:17:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('kmeans').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7377e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d5a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/03 11:20:40 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = spark.read.format('libsvm').load('sample_kmeans_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f84de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|           (3,[],[])|\n",
      "|  1.0|(3,[0,1,2],[0.1,0...|\n",
      "|  2.0|(3,[0,1,2],[0.2,0...|\n",
      "|  3.0|(3,[0,1,2],[9.0,9...|\n",
      "|  4.0|(3,[0,1,2],[9.1,9...|\n",
      "|  5.0|(3,[0,1,2],[9.2,9...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f05482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|           (3,[],[])|\n",
      "|(3,[0,1,2],[0.1,0...|\n",
      "|(3,[0,1,2],[0.2,0...|\n",
      "|(3,[0,1,2],[9.0,9...|\n",
      "|(3,[0,1,2],[9.1,9...|\n",
      "|(3,[0,1,2],[9.2,9...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = data.select('features')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b4306cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(3).setSeed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "813f69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = kmeans.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b60440b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07499999999994544"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wssse = kmeans_model.summary.trainingCost\n",
    "wssse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc49118",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans_model.clusterCenters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dc25223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9.1, 9.1, 9.1]), array([0.05, 0.05, 0.05]), array([0.2, 0.2, 0.2])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58ec5e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|           (3,[],[])|         1|\n",
      "|(3,[0,1,2],[0.1,0...|         1|\n",
      "|(3,[0,1,2],[0.2,0...|         2|\n",
      "|(3,[0,1,2],[9.0,9...|         0|\n",
      "|(3,[0,1,2],[9.1,9...|         0|\n",
      "|(3,[0,1,2],[9.2,9...|         0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = kmeans_model.transform(final_data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4539df7",
   "metadata": {},
   "source": [
    "## Reccomender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463b50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90cb04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/spark-3.2.1-bin-hadoop2.7/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/05 10:56:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('rec_s').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d754a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4554c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Movie Lens data\n",
    "data = spark.read.csv('movielens_ratings.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2d8b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6521e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|movieId|rating|userId|\n",
      "+-------+------+------+\n",
      "|      2|   3.0|     0|\n",
      "|      3|   1.0|     0|\n",
      "|      5|   2.0|     0|\n",
      "|      9|   4.0|     0|\n",
      "|     11|   1.0|     0|\n",
      "+-------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "035007c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|           movieId|            rating|            userId|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              1501|              1501|              1501|\n",
      "|   mean| 49.40572951365756|1.7741505662891406|14.383744170552964|\n",
      "| stddev|28.937034065088994| 1.187276166124803| 8.591040424293272|\n",
      "|    min|                 0|               1.0|                 0|\n",
      "|    max|                99|               5.0|                29|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c3ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "training, test = data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5548fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter=5, regParam=0.01, userCol='userId', itemCol='movieId', ratingCol='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "717c95e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/05 11:04:14 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/05/05 11:04:14 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/05/05 11:04:14 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46329978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|movieId|rating|userId|prediction|\n",
      "+-------+------+------+----------+\n",
      "|      1|   1.0|     4| 0.6757952|\n",
      "|      1|   4.0|    15| 1.8757942|\n",
      "|      6|   1.0|     1|0.41104212|\n",
      "|      6|   1.0|     4| 1.4577866|\n",
      "|      3|   1.0|     9|0.15524265|\n",
      "|      3|   2.0|    22| 1.4984908|\n",
      "|      3|   1.0|    26|  0.381118|\n",
      "|      5|   1.0|     6|0.12843809|\n",
      "|      5|   3.0|    16| 1.1454937|\n",
      "|      5|   2.0|    26| 2.1097898|\n",
      "|      4|   1.0|    14| 2.0674412|\n",
      "|      4|   1.0|    19| 1.4846786|\n",
      "|      2|   4.0|     8| 3.0584147|\n",
      "|      2|   4.0|    10|   4.51926|\n",
      "|      2|   1.0|    19|0.43675283|\n",
      "|      2|   4.0|    21|0.93360054|\n",
      "|      0|   1.0|     3| 1.3465576|\n",
      "|      0|   1.0|     5| 1.4165176|\n",
      "|      0|   1.0|     6| 1.4117017|\n",
      "|      0|   1.0|    22| 0.8711265|\n",
      "+-------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449e8a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 109:======================>                                 (4 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|movieId|rating|userId|prediction|\n",
      "+-------+------+------+----------+\n",
      "|      1|   1.0|     4| 0.6757952|\n",
      "|      1|   4.0|    15| 1.8757942|\n",
      "|      6|   1.0|     1|0.41104212|\n",
      "|      6|   1.0|     4| 1.4577866|\n",
      "|      3|   1.0|     9|0.15524265|\n",
      "|      3|   2.0|    22| 1.4984908|\n",
      "|      3|   1.0|    26|  0.381118|\n",
      "|      5|   1.0|     6|0.12843809|\n",
      "|      5|   3.0|    16| 1.1454937|\n",
      "|      5|   2.0|    26| 2.1097898|\n",
      "|      4|   1.0|    14| 2.0674412|\n",
      "|      4|   1.0|    19| 1.4846786|\n",
      "|      2|   4.0|     8| 3.0584147|\n",
      "|      2|   4.0|    10|   4.51926|\n",
      "|      2|   1.0|    19|0.43675283|\n",
      "|      2|   4.0|    21|0.93360054|\n",
      "|      0|   1.0|     3| 1.3465576|\n",
      "|      0|   1.0|     5| 1.4165176|\n",
      "|      0|   1.0|     6| 1.4117017|\n",
      "|      0|   1.0|    22| 0.8711265|\n",
      "+-------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04cea9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b41ddffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.665487075913309"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(preds)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0390ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_user = test.filter(test['userId']==11).select(['movieId', 'userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e19465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|     13|    11|\n",
      "|     19|    11|\n",
      "|     21|    11|\n",
      "|     30|    11|\n",
      "|     36|    11|\n",
      "|     47|    11|\n",
      "|     67|    11|\n",
      "|     75|    11|\n",
      "|     77|    11|\n",
      "|     78|    11|\n",
      "|     80|    11|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fef9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reccomendations = model.transform(single_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc828710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|     80|    11|  4.049386|\n",
      "|     75|    11| 3.7398398|\n",
      "|     30|    11| 3.6486545|\n",
      "|     36|    11| 3.4465692|\n",
      "|     67|    11| 2.3217723|\n",
      "|     47|    11| 2.1774669|\n",
      "|     21|    11| 1.1505594|\n",
      "|     78|    11| 0.9832475|\n",
      "|     19|    11| 0.6411476|\n",
      "|     13|    11| 0.3785353|\n",
      "|     77|    11|0.13235196|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reccomendations.orderBy('prediction', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea797f",
   "metadata": {},
   "source": [
    "## NLP(Natural Language Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89702f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
